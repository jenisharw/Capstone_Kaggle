 # Capstone_Kaggle( Home Credit Default Risk)
# Business Problem :
Home Credit aims to alleviate the challenges faced by individuals with limited credit history in accessing loans by utilizing advanced statistical and machine learning techniques to identify creditworthy applicants within this underserved population, promoting financial inclusion. The central problem is the difficulty in extending loans to individuals lacking established credit histories, leading them to potentially exploitative lenders. To address this, Home Credit leverages telco and transactional data to predict loan repayment capabilities, enabling informed decision-making. The project's objective is to create an accurate model that assesses the likelihood of default for specific loans, ultimately increasing the acceptance of deserving clients and fostering financial growth. The project's scope encompasses identifying potential loan defaulters through an in-depth analysis of applicant features. 
# Objective
 The primary project objective is to develop a model with the highest precision in predicting the likelihood of loan default for specific cases. Success metrics are defined by the acceptance of a broader group of potential clients capable of repaying loans. Sothe , Objective involves creating a model with the following goals:
Minimize the rejection of loan applications.
Anticipate an applicant's capacity to repay a loan.
Provide secure borrowing choices.
Detect individuals likely to default on loans.
Attain elevated revenue levels.
The project is managed by a team including myself, Jenisha Rawal, Tarun Gulati, and Anjan Kumar.
# Solution my Group have conducted :
Home Credit's solution involves leveraging alternative data to address the challenge of loan application rejections stemming from insufficient credit histories. By utilizing telco and transactional data, the company predicts loan repayment abilities and makes informed decisions regarding application approval. The overarching aim is to provide secure borrowing options, leading to an expanded customer base and increased revenue. Through exploratory data analysis, Home Credit identifies potential defaulters and builds accurate predictive models for default probabilities. Success metrics are linked to a larger pool of accepted applicants with strong loan repayment capabilities. Strategies like upsampling, interaction terms in Model 2, and additional feature engineering in Model 7 have notably improved model performance and loan approval processes.By leveraging advanced analytics techniques and alternative data sources, Home Credit actively contributes to greater financial inclusivity, offering dependable borrowing opportunities to a wider range of applicants. This initiative not only promotes the company's growth but also plays a significant role in fostering a more accessible and equitable financial landscape. Furthermore, by thoroughly analyzing data and addressing class imbalances, Home Credit ensures secure borrowing avenues for a diverse group of applicants, reducing the likelihood of defaults and advancing financial accessibility.

# Contribution in this project:
In EDA I've been actively involved in various critical data preprocessing and analysis tasks. I've utilized the provided code to identify columns with near-zero variance, which is crucial for pinpointing variables that might not significantly impact the model's predictions. Furthermore, I've tackled the challenge of missing data by either replacing null values in the "OWN_CAR_AGE" column or removing columns with substantial missing values. This ensures that the data used for model development is both complete and accurate. Recognizing the categorical variables present in the dataset, I've appropriately emphasized the need to transform them into numerical format, which is essential for machine learning models that require numerical input. Understanding the importance of data transformation to align it with modeling requirements, I've demonstrated my grasp of key preprocessing concepts. These actions collectively reflect my competence in handling data preprocessing, a critical element in building robust and effective machine learning models.


Similarly, As a member my contribution to the modeling involves the analysis and understanding of the data transformations, upsampling, and downsampling strategies, as well as recognizing the implications of these techniques on the model performance.  I have figure it ourt that upsampling does not loose information then downsampling because downsampling may loose information.So, upsampling is generally a better approach as it preserves more data and thus enhances the model's potential for better performance.   
